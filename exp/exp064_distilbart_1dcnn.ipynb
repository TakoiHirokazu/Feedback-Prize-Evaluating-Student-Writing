{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ddd60c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-25 04:01:39.805955: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    }
   ],
   "source": [
    "# ========================================\n",
    "# library\n",
    "# ========================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import StratifiedKFold, KFold,GroupKFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "%matplotlib inline\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "import transformers\n",
    "from transformers import LongformerTokenizer, LongformerModel,AutoTokenizer,RobertaModel,BartModel\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "import logging\n",
    "from ast import literal_eval\n",
    "import sys\n",
    "from contextlib import contextmanager\n",
    "import time\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "496bb758",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================\n",
    "# Constant\n",
    "# ==================\n",
    "ex = \"064\"\n",
    "TRAIN_PATH = \"../data/train.csv\"\n",
    "DATA_DIR = \"../data/distil-bart/\"\n",
    "#FOLD_PATH = \"../data/fe001_train_folds.csv\"\n",
    "if not os.path.exists(f\"../output/exp/ex{ex}\"):\n",
    "    os.makedirs(f\"../output/exp/ex{ex}\")\n",
    "    os.makedirs(f\"../output/exp/ex{ex}/ex{ex}_model\")\n",
    "    \n",
    "OUTPUT_DIR = f\"../output/exp/ex{ex}\"\n",
    "MODEL_PATH_BASE = f\"../output/exp/ex{ex}/ex{ex}_model/ex{ex}\"\n",
    "LOGGER_PATH = f\"../output/exp/ex{ex}/ex{ex}.txt\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "335005e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============\n",
    "# Configs\n",
    "# ===============\n",
    "SEED = 0\n",
    "N_SPLITS = 5\n",
    "SHUFFLE = True\n",
    "num_workers = 4\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "n_epochs = 6\n",
    "max_len = 512\n",
    "weight_decay = 0.1\n",
    "beta = (0.9, 0.98)\n",
    "lr = 2e-5\n",
    "num_warmup_steps_rate = 0.1\n",
    "\n",
    "MODEL_PATH = 'sshleifer/distilbart-cnn-12-6'\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8274a24",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-25 04:02:08,406 - INFO - logger set up\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<RootLogger root (DEBUG)>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ===============\n",
    "# Functions\n",
    "# ===============\n",
    "def set_seed(seed: int = 42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "def setup_logger(out_file=None, stderr=True, stderr_level=logging.INFO, file_level=logging.DEBUG):\n",
    "    LOGGER.handlers = []\n",
    "    LOGGER.setLevel(min(stderr_level, file_level))\n",
    "\n",
    "    if stderr:\n",
    "        handler = logging.StreamHandler(sys.stderr)\n",
    "        handler.setFormatter(FORMATTER)\n",
    "        handler.setLevel(stderr_level)\n",
    "        LOGGER.addHandler(handler)\n",
    "\n",
    "    if out_file is not None:\n",
    "        handler = logging.FileHandler(out_file)\n",
    "        handler.setFormatter(FORMATTER)\n",
    "        handler.setLevel(file_level)\n",
    "        LOGGER.addHandler(handler)\n",
    "\n",
    "    LOGGER.info(\"logger set up\")\n",
    "    return LOGGER\n",
    "\n",
    "\n",
    "@contextmanager\n",
    "def timer(name):\n",
    "    t0 = time.time()\n",
    "    yield \n",
    "    LOGGER.info(f'[{name}] done in {time.time() - t0:.0f} s')\n",
    "    \n",
    "    \n",
    "LOGGER = logging.getLogger()\n",
    "FORMATTER = logging.Formatter(\"%(asctime)s - %(levelname)s - %(message)s\")\n",
    "setup_logger(out_file=LOGGER_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "337faa17",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainDataset(Dataset):\n",
    "    def __init__(self, token,attentiona_mask,label=None):\n",
    "        self.len = len(token)\n",
    "        self.token = token\n",
    "        self.attention_mask = attentiona_mask\n",
    "        self.label = label\n",
    "        #self.get_wids = get_wids # for validation\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # GET TEXT AND WORD LABELS \n",
    "        if self.label is not None:\n",
    "            return {\n",
    "              'token': torch.tensor(self.token[index], dtype=torch.long),\n",
    "              'mask': torch.tensor(self.attention_mask[index], dtype=torch.long),\n",
    "              \"y\":torch.tensor(self.label[index], dtype=torch.float32)\n",
    "               }\n",
    "        else:\n",
    "            return {\n",
    "              'token': torch.tensor(self.token[index], dtype=torch.long),\n",
    "              'mask': torch.tensor(self.attention_mask[index], dtype=torch.long),\n",
    "               }\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "class custom_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(custom_model, self).__init__()\n",
    "        self.backbone = BartModel.from_pretrained(\n",
    "            MODEL_PATH, \n",
    "        )\n",
    "        \n",
    "        #self.dropout = nn.Dropout(p=0.2)\n",
    "        self.ln = nn.LayerNorm(1024)\n",
    "        \n",
    "        self.conv1= nn.Conv1d(1024, 512, kernel_size=3, padding=1)\n",
    "        self.conv2= nn.Conv1d(1024, 512, kernel_size=9, padding=4)\n",
    "        self.conv3= nn.Conv1d(1024, 512, kernel_size=15, padding=7)\n",
    "        self.conv4= nn.Conv1d(1024, 512, kernel_size=31, padding=15)\n",
    "        self.ln1 = nn.Sequential(nn.LayerNorm(512),\n",
    "                                            nn.ReLU(),\n",
    "                                            nn.Dropout(0.2))\n",
    "        self.ln2 = nn.Sequential( nn.LayerNorm(512),\n",
    "                                            nn.ReLU(),\n",
    "                                            nn.Dropout(0.2))\n",
    "        self.ln3 = nn.Sequential( nn.LayerNorm(512),\n",
    "                                            nn.ReLU(),\n",
    "                                            nn.Dropout(0.2))\n",
    "        self.ln4 = nn.Sequential( nn.LayerNorm(512),\n",
    "                                            nn.ReLU(),\n",
    "                                            nn.Dropout(0.2))\n",
    "        \n",
    "        self.linear1 = nn.Sequential(\n",
    "            nn.Linear(2048,1024),\n",
    "            nn.LayerNorm(1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(1024,2),\n",
    "        )\n",
    "        self.linear2 = nn.Sequential(\n",
    "            nn.Linear(2048,1024),\n",
    "            nn.LayerNorm(1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(1024,2),\n",
    "        )\n",
    "        self.linear3 = nn.Sequential(\n",
    "            nn.Linear(2048,1024),\n",
    "            nn.LayerNorm(1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(1024,2),\n",
    "        )\n",
    "        self.linear4 = nn.Sequential(\n",
    "            nn.Linear(2048,1024),\n",
    "            nn.LayerNorm(1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(1024,2),\n",
    "        )\n",
    "        self.linear5 = nn.Sequential(\n",
    "            nn.Linear(2048,1024),\n",
    "            nn.LayerNorm(1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(1024,2),\n",
    "        )\n",
    "        self.linear6 = nn.Sequential(\n",
    "            nn.Linear(2048,1024),\n",
    "            nn.LayerNorm(1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(1024,2),\n",
    "        )\n",
    "        self.linear7 = nn.Sequential(\n",
    "            nn.Linear(2048,1024),\n",
    "            nn.LayerNorm(1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(1024,2),\n",
    "        )\n",
    "        self.linear8 = nn.Sequential(\n",
    "            nn.Linear(2048,1024),\n",
    "            nn.LayerNorm(1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(1024,1),\n",
    "        )\n",
    "    def forward(self, ids, mask):\n",
    "        # pooler\n",
    "        emb = self.backbone(ids, attention_mask=mask)[\"last_hidden_state\"]\n",
    "        output = self.ln(emb)\n",
    "        output = output.permute((0, 2, 1)).contiguous()\n",
    "        output1 = self.conv1(output)\n",
    "        output1 = self.ln1(output1.permute((0, 2, 1)).contiguous())\n",
    "        output2 = self.conv2(output)\n",
    "        output2 = self.ln2(output2.permute((0, 2, 1)).contiguous())\n",
    "        output3 = self.conv3(output)\n",
    "        output3 = self.ln3(output3.permute((0, 2, 1)).contiguous())\n",
    "        output4 = self.conv4(output)\n",
    "        output4 = self.ln4(output4.permute((0, 2, 1)).contiguous())\n",
    "        output_concat = torch.cat([output1,output2,output3,output4],axis=-1)\n",
    "        output2_1 = self.linear1(output_concat)\n",
    "        output2_2 = self.linear2(output_concat)\n",
    "        output2_3 = self.linear3(output_concat)\n",
    "        output2_4 = self.linear4(output_concat)\n",
    "        output2_5 = self.linear5(output_concat)\n",
    "        output2_6 = self.linear6(output_concat)\n",
    "        output2_7= self.linear7(output_concat)\n",
    "        output2_8 = self.linear8(output_concat)\n",
    "        out = torch.cat(\n",
    "            [output2_1,output2_2,output2_3,output2_4,\n",
    "             output2_5,output2_6,output2_7,output2_8], axis=2)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ef8f72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_map_rev = {0:'Lead', 1:'Position', 2:'Evidence', 3:'Claim', 4:'Concluding Statement',\n",
    "             5:'Counterclaim', 6:'Rebuttal', 7:'blank'}\n",
    "\n",
    "def get_preds_collate(dataset, verbose,text_ids, preds, preds_len):\n",
    "    all_predictions = []\n",
    "\n",
    "    for id_num in tqdm(range(len(preds))):\n",
    "    \n",
    "        # GET ID\n",
    "        #if (id_num%100==0)&(verbose): \n",
    "        #    print(id_num,', ',end='')\n",
    "        n = text_ids[id_num]\n",
    "        max_len = int(preds_len[id_num])\n",
    "        # GET TOKEN POSITIONS IN CHARS\n",
    "        name = f'../data/{dataset}/{n}.txt'\n",
    "        txt = open(name, 'r').read()\n",
    "        tokens = tokenizer.encode_plus(txt, max_length=max_len, padding='max_length',\n",
    "                                   truncation=True, return_offsets_mapping=True)\n",
    "        off = tokens['offset_mapping']\n",
    "    \n",
    "        # GET WORD POSITIONS IN CHARS\n",
    "        w = []\n",
    "        blank = True\n",
    "        for i in range(len(txt)):\n",
    "            if (txt[i]!=' ')&(txt[i]!='\\n')&(txt[i]!='\\xa0')&(txt[i]!='\\x85')&(blank==True):\n",
    "                w.append(i)\n",
    "                blank=False\n",
    "            elif (txt[i]==' ')|(txt[i]=='\\n')|(txt[i]=='\\xa0')|(txt[i]=='\\x85'):\n",
    "                blank=True\n",
    "        w.append(1e6)\n",
    "            \n",
    "        # MAPPING FROM TOKENS TO WORDS\n",
    "        word_map = -1 * np.ones(max_len,dtype='int32')\n",
    "        w_i = 0\n",
    "        for i in range(len(off)):\n",
    "            if off[i][1]==0: continue\n",
    "            while off[i][0]>=w[w_i+1]: w_i += 1\n",
    "            word_map[i] = int(w_i)\n",
    "        \n",
    "        # CONVERT TOKEN PREDICTIONS INTO WORD LABELS\n",
    "        ### KEY: ###\n",
    "        # 0: LEAD_B, 1: LEAD_I\n",
    "        # 2: POSITION_B, 3: POSITION_I\n",
    "        # 4: EVIDENCE_B, 5: EVIDENCE_I\n",
    "        # 6: CLAIM_B, 7: CLAIM_I\n",
    "        # 8: CONCLUSION_B, 9: CONCLUSION_I\n",
    "        # 10: COUNTERCLAIM_B, 11: COUNTERCLAIM_I\n",
    "        # 12: REBUTTAL_B, 13: REBUTTAL_I\n",
    "        # 14: NOTHING i.e. O\n",
    "        ### NOTE THESE VALUES ARE DIVIDED BY 2 IN NEXT CODE LINE\n",
    "        pred = preds[id_num,]/2.0\n",
    "    \n",
    "        i = 0\n",
    "        while i<max_len:\n",
    "            prediction = []\n",
    "            start = pred[i]\n",
    "            if start in [0,1,2,3,4,5,6,7]:\n",
    "                prediction.append(word_map[i])\n",
    "                i += 1\n",
    "                if i>=max_len: break\n",
    "                while pred[i]==start+0.5:\n",
    "                    if not word_map[i] in prediction:\n",
    "                        prediction.append(word_map[i])\n",
    "                    i += 1\n",
    "                    if i>=max_len: break\n",
    "            else:\n",
    "                i += 1\n",
    "            prediction = [x for x in prediction if x!=-1]\n",
    "            if len(prediction)>4:\n",
    "                all_predictions.append( (n, target_map_rev[int(start)], \n",
    "                                ' '.join([str(x) for x in prediction]) ) )\n",
    "                \n",
    "    # MAKE DATAFRAME\n",
    "    df = pd.DataFrame(all_predictions)\n",
    "    df.columns = ['id','class','predictionstring']\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def calc_overlap(row):\n",
    "    \"\"\"\n",
    "    Calculates the overlap between prediction and\n",
    "    ground truth and overlap percentages used for determining\n",
    "    true positives.\n",
    "    \"\"\"\n",
    "    set_pred = set(row.predictionstring_pred.split(' '))\n",
    "    set_gt = set(row.predictionstring_gt.split(' '))\n",
    "    # Length of each and intersection\n",
    "    len_gt = len(set_gt)\n",
    "    len_pred = len(set_pred)\n",
    "    inter = len(set_gt.intersection(set_pred))\n",
    "    overlap_1 = inter / len_gt\n",
    "    overlap_2 = inter/ len_pred\n",
    "    return [overlap_1, overlap_2]\n",
    "\n",
    "\n",
    "def score_feedback_comp(pred_df, gt_df):\n",
    "    \"\"\"\n",
    "    A function that scores for the kaggle\n",
    "        Student Writing Competition\n",
    "        \n",
    "    Uses the steps in the evaluation page here:\n",
    "        https://www.kaggle.com/c/feedback-prize-2021/overview/evaluation\n",
    "    \"\"\"\n",
    "    gt_df = gt_df[['id','discourse_type','predictionstring']] \\\n",
    "        .reset_index(drop=True).copy()\n",
    "    pred_df = pred_df[['id','class','predictionstring']] \\\n",
    "        .reset_index(drop=True).copy()\n",
    "    pred_df['pred_id'] = pred_df.index\n",
    "    gt_df['gt_id'] = gt_df.index\n",
    "    # Step 1. all ground truths and predictions for a given class are compared.\n",
    "    joined = pred_df.merge(gt_df,\n",
    "                           left_on=['id','class'],\n",
    "                           right_on=['id','discourse_type'],\n",
    "                           how='outer',\n",
    "                           suffixes=('_pred','_gt')\n",
    "                          )\n",
    "    joined['predictionstring_gt'] = joined['predictionstring_gt'].fillna(' ')\n",
    "    joined['predictionstring_pred'] = joined['predictionstring_pred'].fillna(' ')\n",
    "\n",
    "    joined['overlaps'] = joined.apply(calc_overlap, axis=1)\n",
    "\n",
    "    # 2. If the overlap between the ground truth and prediction is >= 0.5, \n",
    "    # and the overlap between the prediction and the ground truth >= 0.5,\n",
    "    # the prediction is a match and considered a true positive.\n",
    "    # If multiple matches exist, the match with the highest pair of overlaps is taken.\n",
    "    joined['overlap1'] = joined['overlaps'].apply(lambda x: eval(str(x))[0])\n",
    "    joined['overlap2'] = joined['overlaps'].apply(lambda x: eval(str(x))[1])\n",
    "\n",
    "\n",
    "    joined['potential_TP'] = (joined['overlap1'] >= 0.5) & (joined['overlap2'] >= 0.5)\n",
    "    joined['max_overlap'] = joined[['overlap1','overlap2']].max(axis=1)\n",
    "    tp_pred_ids = joined.query('potential_TP') \\\n",
    "        .sort_values('max_overlap', ascending=False) \\\n",
    "        .groupby(['id','predictionstring_gt']).first()['pred_id'].values\n",
    "\n",
    "    # 3. Any unmatched ground truths are false negatives\n",
    "    # and any unmatched predictions are false positives.\n",
    "    fp_pred_ids = [p for p in joined['pred_id'].unique() if p not in tp_pred_ids]\n",
    "\n",
    "    matched_gt_ids = joined.query('potential_TP')['gt_id'].unique()\n",
    "    unmatched_gt_ids = [c for c in joined['gt_id'].unique() if c not in matched_gt_ids]\n",
    "\n",
    "    # Get numbers of each type\n",
    "    TP = len(tp_pred_ids)\n",
    "    FP = len(fp_pred_ids)\n",
    "    FN = len(unmatched_gt_ids)\n",
    "    #calc microf1\n",
    "    my_f1_score = TP / (TP + 0.5*(FP+FN))\n",
    "    return my_f1_score\n",
    "\n",
    "def collate(d,train=True):\n",
    "    mask_len = int(d[\"mask\"].sum(axis=1).max())\n",
    "    if train:\n",
    "        return {\"token\" : d['token'][:,:mask_len],\n",
    "                 \"mask\" : d['mask'][:,:mask_len],\n",
    "                 \"y\" : d['y'][:,:mask_len],\n",
    "                  \"max_len\" : mask_len}\n",
    "    else:\n",
    "        return {\"token\" : d['token'][:,:mask_len],\n",
    "                 \"mask\" : d['mask'][:,:mask_len],\n",
    "                  \"max_len\" : mask_len}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2232e1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================\n",
    "# Main\n",
    "# ================================\n",
    "train = pd.read_csv(TRAIN_PATH)\n",
    "IDS = train.id.unique()\n",
    "id_array = np.array(IDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c572ba72",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = np.load(DATA_DIR + f\"targets_{max_len}.npy\")\n",
    "train_tokens = np.load(DATA_DIR + f\"tokens_{max_len}.npy\")\n",
    "train_attention = np.load(DATA_DIR + f\"attention_{max_len}.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cde2c9ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold0:start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-25 04:02:15,085 - INFO - Lock 140448116523664 acquired on /root/.cache/huggingface/transformers/b336fa0b874ea92e3e22f07a7e6f8fa9da01221759c33abeb2679d6d98fe7755.585965cf7e82e4536033cd21d76c486af3d6b1c2a34b3a847840d4e7fe9d8844.lock\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34b87fbd78ff47fe8abb4d1529bf927f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.14G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-25 04:02:42,918 - INFO - Lock 140448116523664 released on /root/.cache/huggingface/transformers/b336fa0b874ea92e3e22f07a7e6f8fa9da01221759c33abeb2679d6d98fe7755.585965cf7e82e4536033cd21d76c486af3d6b1c2a34b3a847840d4e7fe9d8844.lock\n",
      "Some weights of the model checkpoint at sshleifer/distilbart-cnn-12-6 were not used when initializing BartModel: ['final_logits_bias']\n",
      "- This IS expected if you are initializing BartModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BartModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============start epoch:0==============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 780/780 [05:42<00:00,  2.28it/s]\n",
      "100%|██████████| 195/195 [00:32<00:00,  5.94it/s]\n",
      "100%|██████████| 3119/3119 [00:15<00:00, 200.01it/s]\n",
      "2022-02-25 04:09:21,094 - INFO - Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "2022-02-25 04:09:21,095 - INFO - NumExpr defaulting to 8 threads.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Lead 0.7780521262002743\n",
      "Claim 0.5842321921734146\n",
      "Evidence 0.6283592422430613\n",
      "Counterclaim 0.3763109191856878\n",
      "Position 0.6551120448179272\n",
      "Concluding Statement 0.5531205335874226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-25 04:09:24,523 - INFO - 0,0:779,val_score:0.517273585245087\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rebuttal 0.0457280385078219\n",
      "save model weight\n",
      "============start epoch:1==============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 780/780 [05:42<00:00,  2.28it/s]\n",
      "100%|██████████| 195/195 [00:32<00:00,  5.95it/s]\n",
      "100%|██████████| 3119/3119 [00:15<00:00, 199.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Lead 0.823841059602649\n",
      "Claim 0.5803750442269136\n",
      "Evidence 0.6471148126115408\n",
      "Counterclaim 0.43595263724434874\n",
      "Position 0.6988489950180381\n",
      "Concluding Statement 0.6047013155057149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-25 04:16:01,841 - INFO - 0,1:779,val_score:0.5863561747713945\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rebuttal 0.3136593591905565\n",
      "save model weight\n",
      "============start epoch:2==============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 780/780 [05:40<00:00,  2.29it/s]\n",
      "100%|██████████| 195/195 [00:32<00:00,  5.93it/s]\n",
      "100%|██████████| 3119/3119 [00:15<00:00, 199.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Lead 0.8272898200376041\n",
      "Claim 0.6083842890982207\n",
      "Evidence 0.6693012394467397\n",
      "Position 0.6974201264308901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-25 04:22:42,608 - INFO - 0,2:779,val_score:0.5932923858950868\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concluding Statement 0.5683520599250936\n",
      "Counterclaim 0.45215562565720296\n",
      "Rebuttal 0.33014354066985646\n",
      "save model weight\n",
      "============start epoch:3==============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 780/780 [05:40<00:00,  2.29it/s]\n",
      "100%|██████████| 195/195 [00:32<00:00,  5.94it/s]\n",
      "100%|██████████| 3119/3119 [00:15<00:00, 200.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Lead 0.8189701897018971\n",
      "Position 0.7072512647554806\n",
      "Evidence 0.6684369342184671\n",
      "Claim 0.6040623107832884\n",
      "Concluding Statement 0.5927092709270927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-25 04:29:23,034 - INFO - 0,3:779,val_score:0.5876217459418508\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counterclaim 0.4220079410096427\n",
      "Rebuttal 0.29991431019708653\n",
      "============start epoch:4==============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 780/780 [05:41<00:00,  2.29it/s]\n",
      "100%|██████████| 195/195 [00:32<00:00,  5.94it/s]\n",
      "100%|██████████| 3119/3119 [00:15<00:00, 200.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Lead 0.8240593534711181\n",
      "Position 0.7031932773109244\n",
      "Counterclaim 0.44126074498567336\n",
      "Claim 0.601899592944369\n",
      "Evidence 0.6623771224307418\n",
      "Concluding Statement 0.5996457041629761\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-25 04:35:55,944 - INFO - 0,4:779,val_score:0.5960236738750396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rebuttal 0.33972992181947403\n",
      "save model weight\n",
      "============start epoch:5==============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 780/780 [05:41<00:00,  2.29it/s]\n",
      "100%|██████████| 195/195 [00:32<00:00,  5.93it/s]\n",
      "100%|██████████| 3119/3119 [00:15<00:00, 198.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Lead 0.8286092715231788\n",
      "Counterclaim 0.4394167923579688\n",
      "Claim 0.6006071118820469\n",
      "Evidence 0.6595392793857059\n",
      "Position 0.7028851020752489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-25 04:42:37,056 - INFO - 0,5:779,val_score:0.5933062926709771\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concluding Statement 0.6001788908765653\n",
      "Rebuttal 0.32190760059612517\n",
      "fold1:start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at sshleifer/distilbart-cnn-12-6 were not used when initializing BartModel: ['final_logits_bias']\n",
      "- This IS expected if you are initializing BartModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BartModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============start epoch:0==============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 780/780 [05:41<00:00,  2.28it/s]\n",
      "100%|██████████| 195/195 [00:29<00:00,  6.56it/s]\n",
      "100%|██████████| 3119/3119 [00:15<00:00, 199.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evidence 0.6302578440509475\n",
      "Claim 0.5370259600430674\n",
      "Lead 0.7757783490431306\n",
      "Counterclaim 0.2763246143527834\n",
      "Concluding Statement 0.5352112676056338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-25 04:49:11,754 - INFO - 1,0:779,val_score:0.48881178921352675\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Position 0.6624115922028635\n",
      "Rebuttal 0.004672897196261682\n",
      "save model weight\n",
      "============start epoch:1==============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 780/780 [05:41<00:00,  2.28it/s]\n",
      "100%|██████████| 195/195 [00:29<00:00,  6.57it/s]\n",
      "100%|██████████| 3119/3119 [00:15<00:00, 200.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Claim 0.5966533325821173\n",
      "Evidence 0.655165971227502\n",
      "Lead 0.8187737384698861\n",
      "Counterclaim 0.45151359671626473\n",
      "Rebuttal 0.3083197389885807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-25 04:55:44,245 - INFO - 1,1:779,val_score:0.5840687160902261\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Position 0.6874149659863945\n",
      "Concluding Statement 0.5706396686608376\n",
      "save model weight\n",
      "============start epoch:2==============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 780/780 [05:41<00:00,  2.28it/s]\n",
      "100%|██████████| 195/195 [00:29<00:00,  6.55it/s]\n",
      "100%|██████████| 3119/3119 [00:15<00:00, 199.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Position 0.7046107076507346\n",
      "Evidence 0.6502566639866411\n",
      "Claim 0.5919734356214577\n",
      "Lead 0.8260629486471562\n",
      "Counterclaim 0.4644595910418695\n",
      "Rebuttal 0.35057915057915057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-25 05:02:21,850 - INFO - 1,2:779,val_score:0.5949943874362367\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concluding Statement 0.5770182145266471\n",
      "save model weight\n",
      "============start epoch:3==============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 780/780 [05:41<00:00,  2.28it/s]\n",
      "100%|██████████| 195/195 [00:29<00:00,  6.57it/s]\n",
      "100%|██████████| 3119/3119 [00:15<00:00, 199.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Position 0.7079735906551549\n",
      "Evidence 0.6640111050757439\n",
      "Claim 0.6170922412379025\n",
      "Lead 0.8188668713368685\n",
      "Counterclaim 0.4644644644644645\n",
      "Rebuttal 0.36525612472160357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-25 05:08:59,260 - INFO - 1,3:779,val_score:0.6034833555425694\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concluding Statement 0.5867190913062472\n",
      "save model weight\n",
      "============start epoch:4==============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 780/780 [05:41<00:00,  2.28it/s]\n",
      "100%|██████████| 195/195 [00:29<00:00,  6.55it/s]\n",
      "100%|██████████| 3119/3119 [00:15<00:00, 200.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Claim 0.6114222896927184\n",
      "Evidence 0.6589010471820214\n",
      "Lead 0.8210526315789474\n",
      "Counterclaim 0.47019867549668876\n",
      "Rebuttal 0.36621717530163234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-25 05:15:37,180 - INFO - 1,4:779,val_score:0.6028526742246866\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Position 0.702020202020202\n",
      "Concluding Statement 0.5901566983005959\n",
      "============start epoch:5==============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 780/780 [05:41<00:00,  2.28it/s]\n",
      "100%|██████████| 195/195 [00:29<00:00,  6.55it/s]\n",
      "100%|██████████| 3119/3119 [00:15<00:00, 198.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evidence 0.6586988519281719\n",
      "Claim 0.6084225097162328\n",
      "Lead 0.825979720471362\n",
      "Counterclaim 0.46049442559379544\n",
      "Rebuttal 0.36755204594400576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-25 05:22:07,927 - INFO - 1,5:779,val_score:0.6016270442000201\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Position 0.7037224187299983\n",
      "Concluding Statement 0.5865193370165745\n",
      "fold2:start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at sshleifer/distilbart-cnn-12-6 were not used when initializing BartModel: ['final_logits_bias']\n",
      "- This IS expected if you are initializing BartModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BartModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============start epoch:0==============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 780/780 [05:41<00:00,  2.29it/s]\n",
      "100%|██████████| 195/195 [00:29<00:00,  6.58it/s]\n",
      "100%|██████████| 3119/3119 [00:15<00:00, 198.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Lead 0.8036129032258065\n",
      "Claim 0.5541035023523262\n",
      "Position 0.5987887963663892\n",
      "Evidence 0.6420450976697444\n",
      "Concluding Statement 0.5476025017373176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-25 05:28:41,995 - INFO - 2,0:779,val_score:0.5028034465917984\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counterclaim 0.30100755667506296\n",
      "Rebuttal 0.07246376811594203\n",
      "save model weight\n",
      "============start epoch:1==============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 780/780 [05:41<00:00,  2.29it/s]\n",
      "100%|██████████| 195/195 [00:29<00:00,  6.57it/s]\n",
      "100%|██████████| 3119/3119 [00:15<00:00, 195.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Lead 0.8083311363037173\n",
      "Position 0.6590216807023831\n",
      "Claim 0.592015359421763\n",
      "Evidence 0.6545477183589616\n",
      "Concluding Statement 0.5574387947269304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-25 05:35:14,642 - INFO - 2,1:779,val_score:0.5686244189662427\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counterclaim 0.41329639889196673\n",
      "Rebuttal 0.29571984435797666\n",
      "save model weight\n",
      "============start epoch:2==============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 780/780 [05:41<00:00,  2.29it/s]\n",
      "100%|██████████| 195/195 [00:29<00:00,  6.58it/s]\n",
      "100%|██████████| 3119/3119 [00:15<00:00, 197.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Lead 0.8207572147206778\n",
      "Position 0.6745463625769935\n",
      "Claim 0.5894010242707638\n",
      "Evidence 0.6513783849719443\n",
      "Concluding Statement 0.5776271186440678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-25 05:41:51,926 - INFO - 2,2:779,val_score:0.5895133738887838\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counterclaim 0.47163912460920054\n",
      "Rebuttal 0.34124438742783836\n",
      "save model weight\n",
      "============start epoch:3==============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 780/780 [05:41<00:00,  2.28it/s]\n",
      "100%|██████████| 195/195 [00:29<00:00,  6.57it/s]\n",
      "100%|██████████| 3119/3119 [00:15<00:00, 198.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Lead 0.8208759506949909\n",
      "Position 0.6662123019253706\n",
      "Claim 0.6017986780799653\n",
      "Evidence 0.6636439565684286\n",
      "Concluding Statement 0.591304347826087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-25 05:48:29,788 - INFO - 2,3:779,val_score:0.5955805823922206\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counterclaim 0.46371681415929206\n",
      "Rebuttal 0.3615120274914089\n",
      "save model weight\n",
      "============start epoch:4==============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 780/780 [05:41<00:00,  2.28it/s]\n",
      "100%|██████████| 195/195 [00:29<00:00,  6.58it/s]\n",
      "100%|██████████| 3119/3119 [00:15<00:00, 196.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Lead 0.8075067024128686\n",
      "Position 0.675114039533705\n",
      "Claim 0.5982525460515332\n",
      "Evidence 0.6683429118773946\n",
      "Concluding Statement 0.5784003615002259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-25 05:55:07,478 - INFO - 2,4:779,val_score:0.5908054019601755\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counterclaim 0.45490981963927857\n",
      "Rebuttal 0.35311143270622286\n",
      "============start epoch:5==============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 780/780 [05:41<00:00,  2.29it/s]\n",
      "100%|██████████| 195/195 [00:29<00:00,  6.57it/s]\n",
      "100%|██████████| 3119/3119 [00:15<00:00, 198.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Lead 0.81293057763646\n",
      "Position 0.6738609112709832\n",
      "Claim 0.5973602737493889\n",
      "Evidence 0.6664315108759553\n",
      "Concluding Statement 0.5864527629233511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-25 06:01:37,704 - INFO - 2,5:779,val_score:0.5932029047136043\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counterclaim 0.46276346604215457\n",
      "Rebuttal 0.3526208304969367\n",
      "fold3:start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at sshleifer/distilbart-cnn-12-6 were not used when initializing BartModel: ['final_logits_bias']\n",
      "- This IS expected if you are initializing BartModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BartModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============start epoch:0==============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 780/780 [05:41<00:00,  2.29it/s]\n",
      "100%|██████████| 195/195 [00:29<00:00,  6.58it/s]\n",
      "100%|██████████| 3119/3119 [00:15<00:00, 197.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Position 0.637253157801103\n",
      "Claim 0.5715692173056938\n",
      "Evidence 0.6478603872818551\n",
      "Concluding Statement 0.4837991590403166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-25 06:08:11,723 - INFO - 3,0:779,val_score:0.5078916965592497\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lead 0.7916230366492146\n",
      "Counterclaim 0.3783783783783784\n",
      "Rebuttal 0.0447585394581861\n",
      "save model weight\n",
      "============start epoch:1==============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 780/780 [05:41<00:00,  2.28it/s]\n",
      "100%|██████████| 195/195 [00:29<00:00,  6.59it/s]\n",
      "100%|██████████| 3119/3119 [00:15<00:00, 197.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Position 0.6731980405878236\n",
      "Claim 0.5529339098208771\n",
      "Evidence 0.6653788107455478\n",
      "Concluding Statement 0.5884187082405345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-25 06:14:44,139 - INFO - 3,1:779,val_score:0.571811084457211\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lead 0.813175230566535\n",
      "Counterclaim 0.44097035040431265\n",
      "Rebuttal 0.26860254083484575\n",
      "save model weight\n",
      "============start epoch:2==============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 780/780 [05:41<00:00,  2.28it/s]\n",
      "100%|██████████| 195/195 [00:29<00:00,  6.58it/s]\n",
      "100%|██████████| 3119/3119 [00:15<00:00, 199.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Position 0.6900369003690037\n",
      "Claim 0.6015395691421609\n",
      "Evidence 0.6682929804232481\n",
      "Concluding Statement 0.5816804100735458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-25 06:21:21,281 - INFO - 3,2:779,val_score:0.5930755472679463\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lead 0.816833018613434\n",
      "Counterclaim 0.44552319309600863\n",
      "Rebuttal 0.34762275915822294\n",
      "save model weight\n",
      "============start epoch:3==============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 780/780 [05:41<00:00,  2.29it/s]\n",
      "100%|██████████| 195/195 [00:29<00:00,  6.59it/s]\n",
      "100%|██████████| 3119/3119 [00:15<00:00, 198.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Position 0.6805221573342494\n",
      "Claim 0.58921579595033\n",
      "Evidence 0.670909415333373\n",
      "Concluding Statement 0.5889109785730064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-25 06:27:58,300 - INFO - 3,3:779,val_score:0.5832633120032565\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lead 0.8231028231028231\n",
      "Counterclaim 0.42393736017897093\n",
      "Rebuttal 0.30624465355004277\n",
      "============start epoch:4==============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 780/780 [05:41<00:00,  2.28it/s]\n",
      "100%|██████████| 195/195 [00:29<00:00,  6.58it/s]\n",
      "100%|██████████| 3119/3119 [00:15<00:00, 198.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Position 0.6875526360114536\n",
      "Claim 0.5999444290080578\n",
      "Evidence 0.6685579196217494\n",
      "Concluding Statement 0.5897714907508161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-25 06:34:28,878 - INFO - 3,4:779,val_score:0.592102441353014\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lead 0.8114710568242167\n",
      "Counterclaim 0.44929006085192696\n",
      "Rebuttal 0.3381294964028777\n",
      "============start epoch:5==============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 780/780 [05:41<00:00,  2.28it/s]\n",
      "100%|██████████| 195/195 [00:29<00:00,  6.58it/s]\n",
      "100%|██████████| 3119/3119 [00:15<00:00, 198.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Position 0.6886521224420767\n",
      "Claim 0.6004671628008039\n",
      "Evidence 0.6674122910289616\n",
      "Concluding Statement 0.5846153846153846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-25 06:40:59,309 - INFO - 3,5:779,val_score:0.5911651341407024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lead 0.8133368338146495\n",
      "Counterclaim 0.4392523364485981\n",
      "Rebuttal 0.344419807834442\n",
      "fold4:start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at sshleifer/distilbart-cnn-12-6 were not used when initializing BartModel: ['final_logits_bias']\n",
      "- This IS expected if you are initializing BartModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BartModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============start epoch:0==============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 780/780 [05:41<00:00,  2.29it/s]\n",
      "100%|██████████| 195/195 [00:29<00:00,  6.60it/s]\n",
      "100%|██████████| 3118/3118 [00:15<00:00, 199.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Lead 0.7914605571465764\n",
      "Evidence 0.6283121597096188\n",
      "Concluding Statement 0.5359565807327001\n",
      "Position 0.5775628626692456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-25 06:47:33,299 - INFO - 4,0:779,val_score:0.4996304957519456\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Claim 0.5348496394864881\n",
      "Counterclaim 0.37942122186495175\n",
      "Rebuttal 0.049850448654037885\n",
      "save model weight\n",
      "============start epoch:1==============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 780/780 [05:41<00:00,  2.28it/s]\n",
      "100%|██████████| 195/195 [00:29<00:00,  6.61it/s]\n",
      "100%|██████████| 3118/3118 [00:15<00:00, 196.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Lead 0.8172739541160594\n",
      "Evidence 0.6280199411990285\n",
      "Concluding Statement 0.5804694048616932\n",
      "Position 0.6826955638333898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-25 06:54:05,632 - INFO - 4,1:779,val_score:0.5538474358837552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Claim 0.5593340417995041\n",
      "Counterclaim 0.34772182254196643\n",
      "Rebuttal 0.2614173228346457\n",
      "save model weight\n",
      "============start epoch:2==============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 780/780 [05:41<00:00,  2.28it/s]\n",
      "100%|██████████| 195/195 [00:29<00:00,  6.59it/s]\n",
      "100%|██████████| 3118/3118 [00:15<00:00, 197.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Lead 0.8176972281449894\n",
      "Evidence 0.6568270092620256\n",
      "Claim 0.5805038335158818\n",
      "Position 0.6878773046173927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-25 07:00:42,947 - INFO - 4,2:779,val_score:0.5824983380621792\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concluding Statement 0.5640565402737268\n",
      "Counterclaim 0.45366795366795365\n",
      "Rebuttal 0.31685849695328366\n",
      "save model weight\n",
      "============start epoch:3==============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 780/780 [05:41<00:00,  2.28it/s]\n",
      "100%|██████████| 195/195 [00:29<00:00,  6.60it/s]\n",
      "100%|██████████| 3118/3118 [00:15<00:00, 195.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Lead 0.8238045738045738\n",
      "Evidence 0.6479827173468792\n",
      "Claim 0.5927643284628242\n",
      "Position 0.6812045690550363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-25 07:07:20,691 - INFO - 4,3:779,val_score:0.5862026715931343\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concluding Statement 0.5689964157706093\n",
      "Counterclaim 0.4455861746847268\n",
      "Rebuttal 0.34307992202729043\n",
      "save model weight\n",
      "============start epoch:4==============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 780/780 [05:41<00:00,  2.29it/s]\n",
      "100%|██████████| 195/195 [00:29<00:00,  6.61it/s]\n",
      "100%|██████████| 3118/3118 [00:15<00:00, 198.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Lead 0.8193288590604026\n",
      "Evidence 0.65476611287852\n",
      "Claim 0.5966432051976177\n",
      "Position 0.6875420875420876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-25 07:13:58,068 - INFO - 4,4:779,val_score:0.5894205840941954\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concluding Statement 0.5730088495575221\n",
      "Counterclaim 0.45161290322580644\n",
      "Rebuttal 0.343042071197411\n",
      "save model weight\n",
      "============start epoch:5==============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 780/780 [05:40<00:00,  2.29it/s]\n",
      "100%|██████████| 195/195 [00:29<00:00,  6.59it/s]\n",
      "100%|██████████| 3118/3118 [00:15<00:00, 198.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Lead 0.8181818181818182\n",
      "Claim 0.5939163898993094\n",
      "Evidence 0.6524830962928422\n",
      "Position 0.6875315497223624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-25 07:20:35,382 - INFO - 4,5:779,val_score:0.5865376238995389\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concluding Statement 0.5784903139612558\n",
      "Counterclaim 0.44599627560521415\n",
      "Rebuttal 0.32916392363396973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-25 07:20:35,601 - INFO - [distilbart_large] done in 11901 s\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# train\n",
    "# ================================\n",
    "with timer(\"distilbart_large\"):\n",
    "    set_seed(SEED)\n",
    "    oof = pd.DataFrame()\n",
    "    oof_pred = np.ndarray((0,max_len,15))\n",
    "    kf = KFold(n_splits=N_SPLITS, shuffle=SHUFFLE, random_state=SEED)\n",
    "    for fold, (train_idx, valid_idx) in enumerate(kf.split(id_array)):\n",
    "        print(f\"fold{fold}:start\")\n",
    "        x_train_token, x_train_attention, y_train  = train_tokens[train_idx], train_attention[train_idx], targets[train_idx]\n",
    "        x_val_token, x_val_attention, y_val  = train_tokens[valid_idx], train_attention[valid_idx], targets[valid_idx]\n",
    "        train_val = train[train.id.isin(id_array[valid_idx])].reset_index(drop=True)\n",
    "        \n",
    "        # dataset\n",
    "        train_ = TrainDataset( x_train_token, x_train_attention, y_train)\n",
    "        val_ = TrainDataset( x_val_token, x_val_attention, y_val)\n",
    "        \n",
    "        # loader\n",
    "        train_loader = DataLoader(dataset=train_, batch_size=BATCH_SIZE, shuffle = True ,pin_memory=True)\n",
    "        val_loader = DataLoader(dataset=val_, batch_size=BATCH_SIZE, shuffle = False , pin_memory=True)\n",
    "        \n",
    "        # model\n",
    "        model = custom_model()\n",
    "        model = model.to(device)\n",
    "        \n",
    "        # optimizer, scheduler\n",
    "        param_optimizer = list(model.named_parameters())\n",
    "        no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
    "        optimizer_grouped_parameters = [\n",
    "            {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': weight_decay},\n",
    "            {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "        ]\n",
    "        optimizer = AdamW(optimizer_grouped_parameters,\n",
    "                          lr=lr,\n",
    "                          betas=beta,\n",
    "                          weight_decay=weight_decay,\n",
    "                          )\n",
    "        num_train_optimization_steps = int(len(train_loader) * n_epochs)\n",
    "        num_warmup_steps = int(num_train_optimization_steps * num_warmup_steps_rate)\n",
    "        scheduler = get_linear_schedule_with_warmup(optimizer,\n",
    "                                                    num_warmup_steps=num_warmup_steps,\n",
    "                                                    num_training_steps=num_train_optimization_steps)\n",
    "        \n",
    "        criterion = nn.BCEWithLogitsLoss()\n",
    "        best_val = 0\n",
    "        \n",
    "        for epoch in range(n_epochs):\n",
    "            print(f\"============start epoch:{epoch}==============\")\n",
    "            model.train() \n",
    "            val_losses_batch = []\n",
    "            scaler = GradScaler()\n",
    "            for i, d in tqdm(enumerate(train_loader),total=len(train_loader)):\n",
    "                d = collate(d)\n",
    "                ids = d['token'].to(device)\n",
    "                mask = d['mask'].to(device)\n",
    "                labels = d['y'].to(device)\n",
    "                #labels = labels.unsqueeze(-1)\n",
    "                optimizer.zero_grad()\n",
    "                with autocast():\n",
    "                    output = model(ids,mask)\n",
    "                    loss = criterion(output[mask == 1], labels[mask == 1])\n",
    "                scaler.scale(loss).backward()\n",
    "                #torch.nn.utils.clip_grad_norm_(model.parameters(), clip_grad_norm)\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "                scheduler.step()\n",
    "            \n",
    "            y_pred2 = []\n",
    "            val_preds = np.ndarray((0,max_len,15))\n",
    "            val_len = np.ndarray(0)\n",
    "            model.eval()  # switch model to the evaluation mode\n",
    "            with torch.no_grad():  \n",
    "                # Predicting on validation set\n",
    "                \n",
    "                for d in tqdm(val_loader,total=len(val_loader)):\n",
    "                    # =========================\n",
    "                    # data loader\n",
    "                    # =========================\n",
    "                    d = collate(d)\n",
    "                    ids = d['token'].to(device)\n",
    "                    mask = d['mask'].to(device)\n",
    "                    with autocast():\n",
    "                        outputs = model(ids, mask)\n",
    "                    outputs = np.concatenate([outputs.sigmoid().detach().cpu().numpy(),np.zeros([len(outputs),max_len - d[\"max_len\"],15])],axis=1)\n",
    "                    val_preds = np.concatenate([val_preds, outputs], axis=0)\n",
    "                    val_len = np.concatenate([val_len,np.array([d[\"max_len\"] for i in range(len(ids))])],axis=0)\n",
    "            val_preds_max = np.argmax(val_preds,axis=-1)\n",
    "            oof_ = get_preds_collate( dataset='train', verbose=True, text_ids=id_array[valid_idx],\n",
    "                                      preds = val_preds_max,preds_len=val_len)      \n",
    "            # COMPUTE F1 SCORE\n",
    "            f1s = []\n",
    "            CLASSES = oof_['class'].unique()\n",
    "            print()\n",
    "            for c in CLASSES:\n",
    "                pred_df = oof_.loc[oof_['class']==c].copy()\n",
    "                gt_df = train_val.loc[train_val['discourse_type']==c].copy()\n",
    "                f1 = score_feedback_comp(pred_df, gt_df)\n",
    "                print(c,f1)\n",
    "                f1s.append(f1)\n",
    "            score = np.mean(f1s)\n",
    "            LOGGER.info(f'{fold},{epoch}:{i},val_score:{score}')\n",
    "            if best_val < score:\n",
    "                print(\"save model weight\")\n",
    "                best_val = score\n",
    "                best_val_preds = val_preds\n",
    "                oof_best = oof_.copy()\n",
    "                torch.save(model.state_dict(), MODEL_PATH_BASE + f\"_{fold}.pth\") # Saving current best model\n",
    "        oof_best[\"fold\"] = fold\n",
    "        oof_best.to_csv(OUTPUT_DIR + f\"/ex{ex}_oof_{fold}.csv\",index=False)\n",
    "        np.save(OUTPUT_DIR + f\"/ex{ex}_oof_npy_{fold}.npy\",best_val_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a97f75df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lead 0.8203721630633538\n",
      "Position 0.6912221471978393\n",
      "Counterclaim 0.45390345361323403\n",
      "Claim 0.6038324372075776\n",
      "Evidence 0.6626337162639706\n",
      "Concluding Statement 0.5867007447230423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-25 07:20:54,477 - INFO - CV:0.5957643621259502\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rebuttal 0.35168587281263336\n"
     ]
    }
   ],
   "source": [
    "oof = pd.DataFrame()\n",
    "for i in range(5):\n",
    "    oof__ = pd.read_csv(OUTPUT_DIR + f\"/ex{ex}_oof_{i}.csv\")\n",
    "    oof = pd.concat([oof,oof__]).reset_index(drop=True)\n",
    "# COMPUTE F1 SCORE\n",
    "f1s = []\n",
    "CLASSES = oof['class'].unique()\n",
    "for c in CLASSES:\n",
    "    pred_df = oof.loc[oof['class']==c].copy()\n",
    "    gt_df = train.loc[train['discourse_type']==c].copy()\n",
    "    f1 = score_feedback_comp(pred_df, gt_df)\n",
    "    print(c,f1)\n",
    "    f1s.append(f1)\n",
    "score = np.mean(f1s)\n",
    "LOGGER.info(f'CV:{score}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
